{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMVA Convolutional Neural Network tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial explaining how to train a simple Convolutional Neural Network, given the ECAL images dataset.\n",
    "The dataset is consisted of several branches, where each event is a flat array of 1024 elements. That means, each image is a 32 by 32 pixels with only one channel. One event is either classified as a photon or electron.\n",
    "\n",
    "Therefore, we create a Convolutional Neural Network consisted of the following layers: Convolutional Layer with 12 2 by 2 filters, striding and zero padding one in both dimensions, Max Pool Layer with 6 by 6 frames and striding 1 in both dimensions, and finally two Dense Layers with 512 and 32 units respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the photon input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1034h"
     ]
    }
   ],
   "source": [
    "TMVA::Tools::Instance();\n",
    "\n",
    "// Load the photon input\n",
    "TFile *photonInput(0);\n",
    "TString photonFileName = \"dataset/SinglePhotonPt50_FEVTDEBUG_n250k_IMG_CROPS32.root\";\n",
    "photonInput = TFile::Open(photonFileName);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the electron input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Load the electron input\n",
    "TFile *electronInput(0);\n",
    "TString electronFileName = \"dataset/SingleElectronPt50_FEVTDEBUG_n250k_IMG_CROPS32.root\";\n",
    "electronInput = TFile::Open(electronFileName);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the output file and the factory object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Create a ROOT output file where TMVA will store ntuples, histograms, etc.\n",
    "TString outfileName(\"results/TMVA_MethodDL.root\");\n",
    "TFile *outputFile = TFile::Open(outfileName, \"RECREATE\");\n",
    "\n",
    "// Create a factory for booking the method\n",
    "TMVA::Factory *factory = new TMVA::Factory(\"TMVAClassification\", outputFile,\n",
    "                        \"!V:!Silent:Color:DrawProgressBar:Transformations=I:AnalysisType=Classification\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loader object and assign the appropriate trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMVA::DataLoader *dataloader = new TMVA::DataLoader(\"dataset\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree RHTree of type Signal with 249278 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree RHTree of type Background with 249355 events\n"
     ]
    }
   ],
   "source": [
    "// Get the trees\n",
    "TTree *signalTree = (TTree *)photonInput->Get(\"RHTree\");\n",
    "TTree *background = (TTree *)electronInput->Get(\"RHTree\");\n",
    "\n",
    "// global event weights per tree\n",
    "Double_t signalWeight = 1.0;\n",
    "Double_t backgroundWeight = 1.0;\n",
    "\n",
    "// Add signal and background trees\n",
    "dataloader->AddSignalTree(signalTree, signalWeight);\n",
    "dataloader->AddBackgroundTree(background, backgroundWeight);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Prepare training and testing data\n",
    "TCut mycuts = \"\";\n",
    "TCut mycutb = \"\";\n",
    "\n",
    "dataloader->PrepareTrainingAndTestTree(mycuts, mycutb, \n",
    "                            \"nTrain_Signal=10000:nTrain_Background=10000:SplitMode=Random:NormMode=NumEvents:!V\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the strings for the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Input Layout\n",
    "TString inputLayoutString(\"InputLayout=1|32|32\");\n",
    "\n",
    "// General layout.\n",
    "TString layoutString(\"Layout=CONV|12|2|2|1|1|1|1|TANH,MAXPOOL|6|6|1|1,RESHAPE|1|1|9408|FLAT,DENSE|512|TANH,DENSE|32|\"\n",
    "                     \"TANH,DENSE|2|LINEAR\");\n",
    "\n",
    "// Training strategies.\n",
    "TString training0(\"LearningRate=1e-1,Momentum=0.9,Repetitions=1,\"\n",
    "                  \"ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,\"\n",
    "                  \"WeightDecay=1e-4,Regularization=L2,\"\n",
    "                  \"DropConfig=0.0+0.5+0.5+0.5, Multithreading=True\");\n",
    "TString training1(\"LearningRate=1e-2,Momentum=0.9,Repetitions=1,\"\n",
    "                  \"ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,\"\n",
    "                  \"WeightDecay=1e-4,Regularization=L2,\"\n",
    "                  \"DropConfig=0.0+0.0+0.0+0.0, Multithreading=True\");\n",
    "TString training2(\"LearningRate=1e-3,Momentum=0.0,Repetitions=1,\"\n",
    "                  \"ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,\"\n",
    "                  \"WeightDecay=1e-4,Regularization=L2,\"\n",
    "                  \"DropConfig=0.0+0.0+0.0+0.0, Multithreading=True\");\n",
    "TString trainingStrategyString(\"TrainingStrategy=\");\n",
    "trainingStrategyString += training0 + \"|\" + training1 + \"|\" + training2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "// General Options.\n",
    "TString cnnOptions(\"!H:V:ErrorStrategy=CROSSENTROPY:\"\n",
    "                   \"WeightInitialization=XAVIERUNIFORM\");\n",
    "\n",
    "// Concatenate all option strings\n",
    "cnnOptions.Append(\":\");\n",
    "cnnOptions.Append(inputLayoutString);\n",
    "\n",
    "cnnOptions.Append(\":\");\n",
    "cnnOptions.Append(layoutString);\n",
    "\n",
    "cnnOptions.Append(\":\");\n",
    "cnnOptions.Append(trainingStrategyString);\n",
    "\n",
    "cnnOptions.Append(\":Architecture=CPU\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_CPU\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:WeightInitialization=XAVIERUNIFORM:InputLayout=1|32|32:Layout=CONV|12|2|2|1|1|1|1|TANH,MAXPOOL|6|6|1|1,RESHAPE|1|1|9408|FLAT,DENSE|512|TANH,DENSE|32|TANH,DENSE|2|LINEAR:TrainingStrategy=LearningRate=1e-1,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=L2,DropConfig=0.0+0.5+0.5+0.5, Multithreading=True|LearningRate=1e-2,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=L2,DropConfig=0.0+0.0+0.0+0.0, Multithreading=True|LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=L2,DropConfig=0.0+0.0+0.0+0.0, Multithreading=True:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:WeightInitialization=XAVIERUNIFORM:InputLayout=1|32|32:Layout=CONV|12|2|2|1|1|1|1|TANH,MAXPOOL|6|6|1|1,RESHAPE|1|1|9408|FLAT,DENSE|512|TANH,DENSE|32|TANH,DENSE|2|LINEAR:TrainingStrategy=LearningRate=1e-1,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=L2,DropConfig=0.0+0.5+0.5+0.5, Multithreading=True|LearningRate=1e-2,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=L2,DropConfig=0.0+0.0+0.0+0.0, Multithreading=True|LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=L2,DropConfig=0.0+0.0+0.0+0.0, Multithreading=True:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|32|32\" [The Layout of the input]\n",
      "                         :     Layout: \"CONV|12|2|2|1|1|1|1|TANH,MAXPOOL|6|6|1|1,RESHAPE|1|1|9408|FLAT,DENSE|512|TANH,DENSE|32|TANH,DENSE|2|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-1,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=L2,DropConfig=0.0+0.5+0.5+0.5,\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 10000\n",
      "                         : Signal     -- testing events             : 239278\n",
      "                         : Signal     -- training and testing events: 249278\n",
      "                         : Background -- training events            : 10000\n",
      "                         : Background -- testing events             : 239355\n",
      "                         : Background -- training and testing events: 249355\n",
      "                         : \n",
      "DataSetInfo              : Correlation matrix (Signal):\n",
      "                         : --------\n",
      "                         :         \n",
      "                         : --------\n",
      "DataSetInfo              : Correlation matrix (Background):\n",
      "                         : --------\n",
      "                         :         \n",
      "                         : --------\n",
      "DataSetFactory           : [dataset] :  \n",
      "                         : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TH1::TH1>: nbins is <=0 - set to nbins = 1\n",
      "Warning in <TH2::TH2>: nbinsy is <=0 - set to nbinsy = 1\n",
      "Warning in <TH2F::LabelsOption>: Cannot sort. No labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : [dataset] : Create Transformation \"I\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Ranking input variables (method unspecific)...\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------\n",
      "                         : Rank : Variable  : Separation\n",
      "                         : -------------------------\n",
      "                         : -------------------------\n",
      "Factory                  : Train method: DL_CPU for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU.\n",
      "                         : \n",
      "                         : Training phase 1 of 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TH1::TH1>: nbins is <=0 - set to nbins = 1\n",
      "Warning in <TH2::TH2>: nbinsy is <=0 - set to nbinsy = 1\n",
      "Warning in <TH2F::LabelsOption>: Cannot sort. No labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         :      Epoch |   Train Err.  Test  Err.     GFLOP/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "TString methodTitle = \"DL_CPU\";\n",
    "factory->BookMethod(dataloader, TMVA::Types::kDL, methodTitle, cnnOptions);\n",
    "\n",
    "// Train MVAs using the set of training events\n",
    "factory->TrainAllMethods();\n",
    "\n",
    "// Save the output\n",
    "outputFile->Close();\n",
    "\n",
    "std::cout << \"==> Wrote root file: \" << outputFile->GetName() << std::endl;\n",
    "std::cout << \"==> TMVAClassification is done!\" << std::endl;\n",
    "\n",
    "delete factory;\n",
    "delete dataloader;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
